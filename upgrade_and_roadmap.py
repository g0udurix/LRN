#!/usr/bin/env python3
"""
LRN — governance & automation finisher (v3)
- Safe to run repeatedly. Idempotent where possible.
- Adds/updates governance files, labels, workflows, branch protection, milestones.
- NEW: self-test and default-branch bootstrap so Actions exist on the default branch.

Usage:
  python upgrade_and_roadmap.py --apply [--no-refresh] [--self-test]
"""
from __future__ import annotations
import os, sys, re, json, time, subprocess, shutil
from pathlib import Path
from datetime import datetime, timezone, timedelta

REPO_SLUG = os.getenv("LRN_REPO", "g0udurix/LRN")
APPLY = "--apply" in sys.argv
SELF_TEST = "--self-test" in sys.argv
NO_REFRESH = "--no-refresh" in sys.argv

# ==================================================================================
# small utils
# ==================================================================================

def ts() -> str:
    return datetime.now(timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ")

def log(msg: str):
    print(msg)
    try:
        Path("logs").mkdir(exist_ok=True)
        with open(Path("logs")/f"pm_fix_{datetime.now(timezone.utc).strftime('%Y%m%dT%H%M%SZ')}.log", "a", encoding="utf-8") as f:
            f.write(msg+"\n")
    except Exception:
        pass

def run(cmd, cwd: Path|None=None, check=False):
    shell = isinstance(cmd, str)
    p = subprocess.run(cmd, cwd=(str(cwd) if cwd else None), capture_output=True, text=True, shell=shell)
    out, err = (p.stdout or "").strip(), (p.stderr or "").strip()
    cmd_str = cmd if shell else " ".join(cmd)
    err_part = ("\n" + err) if err else ""
    log(f"$ {cmd_str}\n[rc={p.returncode}]\n{out}{err_part}")
    if check and p.returncode != 0:
        raise RuntimeError(f"Command failed rc={p.returncode}: {cmd_str}\n{err}")
    return p.returncode, out, err

# ==================================================================================
# git helpers
# ==================================================================================

def default_branch_from_git() -> str|None:
    rc, out, _ = run(["git","symbolic-ref","refs/remotes/origin/HEAD"])  # refs/remotes/origin/<branch>
    if rc == 0 and out:
        return out.strip().split("/")[-1]
    rc, out, _ = run(["git","rev-parse","--abbrev-ref","origin/HEAD"])  # fallback
    if rc == 0 and out:
        return out.strip().split("/")[-1]
    return None

def get_default_branch() -> str:
    return default_branch_from_git() or "master"

def git_pull(repo_dir: Path):
    if (repo_dir/".git").exists():
        run(["git","fetch","--all"], cwd=repo_dir)
        run(["git","pull","--rebase","--autostash"], cwd=repo_dir)


def git_commit_push(repo_dir: Path, message: str) -> bool:
    if not (repo_dir/".git").exists():
        log("[WARN] not a git repo, skipping commit/push"); return False
    run(["git","add","-A"], cwd=repo_dir)
    rc,_,_ = run(["git","diff","--cached","--quiet"], cwd=repo_dir)
    if rc==0:
        log("[OK] no changes to commit"); return False
    run(["git","commit","-m", message], cwd=repo_dir)
    run(["git","push"], cwd=repo_dir)
    return True

# ==================================================================================
# ensure helpers
# ==================================================================================

def ensure_file(path: Path, content: str) -> bool:
    """Write file iff content changed. Returns True if wrote."""
    if path.exists() and path.read_text(encoding="utf-8") == content:
        log(f"[OK] ensure {path} — up-to-date"); return False
    if APPLY:
        path.parent.mkdir(parents=True, exist_ok=True)
        path.write_text(content, encoding="utf-8")
        log(f"[APPLIED] ensure {path} — written")
        return True
    else:
        log(f"[DRY] ensure {path} — would write")
        return False


def ensure_gitignore_lines(repo_dir: Path, lines: list[str]) -> bool:
    gi = repo_dir/".gitignore"
    existing = gi.read_text(encoding="utf-8").splitlines() if gi.exists() else []
    need = [ln for ln in lines if ln not in existing]
    if not need:
        log("[OK] .gitignore — up-to-date"); return False
    if APPLY:
        with open(gi, "a", encoding="utf-8") as f:
            if existing and existing[-1].strip() != "":
                f.write("\n")
            f.write("\n# LRN autogenerated ignores\n")
            for ln in need:
                f.write(ln+"\n")
        log("[APPLIED] .gitignore — appended ignores")
        return True
    else:
        log(f"[DRY] .gitignore — would append: " + ", ".join(need))
        return False

# ==================================================================================
# payloads (shortened where possible)
# ==================================================================================

CONTRIBUTING = """# Contributing to LRN (Humans & AI agents)
- Semantic commits; keep PRs small; cite standards.
- No secrets; reproducible steps; tests/docs for non-trivial changes.
- For AI agents: add an **AI notes** block in PRs (prompts, assumptions, citations).
"""

CODE_OF_CONDUCT = """# Code of Conduct (Humans & AI agents)
Be respectful. Disclose automation in PRs. Don’t paste proprietary standards; summarize & cite. Flag unsafe guidance with references.
"""

SEMANTIC_PR_WF = """name: Semantic PR
on:
  pull_request:
    types: [opened, edited, synchronize, reopened, ready_for_review]
jobs:
  semantic:
    runs-on: ubuntu-latest
    steps:
      - uses: amannn/action-semantic-pull-request@v5
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        with:
          types: |-
            feat, fix, docs, style, refactor, perf, test, build, ci, chore, revert
"""

AUTO_MILESTONE_WF = """name: Auto milestone from labels
on:
  issues:
    types: [opened, edited, labeled, unlabeled, reopened]
  pull_request:
    types: [opened, edited, labeled, unlabeled, reopened, ready_for_review]
  workflow_dispatch:
permissions:
  issues: write
  pull-requests: write
jobs:
  apply:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/github-script@v7
        with:
          script: |
            const item = context.payload.issue || context.payload.pull_request;
            const labels = (item.labels || []).map(l => typeof l === 'string' ? l : l.name);
            const map = {
              'milestone/phase-0': 'Phase 0 – Baseline',
              'milestone/phase-1': 'Phase 1 – Corpus & Standards',
              'milestone/phase-2': 'Phase 2 – Comparison Engine',
              'milestone/phase-3': 'Phase 3 – Annotations & Issues',
              'milestone/phase-4': 'Phase 4 – Guidance UI',
            };
            const key = labels.find(n => (n||'').toLowerCase().startsWith('milestone/'));
            if (!key) return;
            const owner = context.repo.owner, repo = context.repo.repo;
            const {data: ms} = await github.rest.issues.listMilestones({owner, repo, state:'all'});
            const m = ms.find(x => x.title === map[key]);
            if (m) await github.rest.issues.update({owner, repo, issue_number: item.number, milestone: m.number});
"""

LABELS_YML = """labels:
  - { name: area/standards, color: 0366d6, description: Standards mapping & clauses }
  - { name: area/comparison, color: 0e8a16, description: Cross-jurisdiction comparisons }
  - { name: area/extractor, color: 1d76db, description: Crawlers & ingestion }
  - { name: status/Backlog, color: cccccc }
  - { name: status/Todo,    color: 5319e7 }
  - { name: status/Doing,   color: 1d76db }
  - { name: status/Review,  color: fbca04 }
  - { name: status/Blocked, color: b60205 }
  - { name: status/Done,    color: 0e8a16 }
  - { name: priority/P0, color: b60205 }
  - { name: priority/P1, color: d93f0b }
  - { name: priority/P2, color: fbca04 }
  - { name: priority/P3, color: cccccc }
  - { name: milestone/phase-0, color: bfd4f2, description: Phase 0 – Baseline }
  - { name: milestone/phase-1, color: bfd4f2, description: Phase 1 – Corpus & Standards }
  - { name: milestone/phase-2, color: bfd4f2, description: Phase 2 – Comparison Engine }
  - { name: milestone/phase-3, color: bfd4f2, description: Phase 3 – Annotations & Issues }
  - { name: milestone/phase-4, color: bfd4f2, description: Phase 4 – Guidance UI }
"""

LABELS_SYNC_WF = """name: Labels sync
on:
  schedule: [ { cron: '11 3 * * *' } ]
  push: { paths: [ '.github/labels.yml' ] }
  workflow_dispatch:
jobs:
  sync:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: lannonbr/issue-label-manager-action@v3
        env: { GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} }
        with: { delete: true, config-path: .github/labels.yml }
"""

PROJECTS_SYNC_WF = """name: Projects sync (add & fields)
on:
  issues:
    types: [opened, edited, labeled, unlabeled, reopened]
  pull_request:
    types: [opened, edited, labeled, unlabeled, reopened, ready_for_review]
  workflow_dispatch:
jobs:
  add-and-map:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/add-to-project@v1.0.2
        with:
          project-url: https://github.com/users/g0udurix/projects/3
          github-token: ${{ secrets.PROJECTS_PAT }}
      - name: Map labels to fields
        uses: actions/github-script@v7
        env: { PROJECTS_PAT: ${{ secrets.PROJECTS_PAT }} }
        with:
          script: |
            const token = process.env.PROJECTS_PAT; if(!token){ core.warning('PROJECTS_PAT not set'); return }
            const isPR = !!context.payload.pull_request;
            const item = context.payload.issue || context.payload.pull_request;
            const labels = (item.labels || []).map(l => typeof l === 'string' ? l : l.name);
            const priority = (labels.find(l => /^priority\//i.test(l))||'').split('/')?.[1] || null;
            const status   = (labels.find(l => /^status\//i.test(l))||'').split('/')?.[1] || null;
            const { graphql } = require('@octokit/graphql');
            const ghgql = graphql.defaults({ headers: { authorization: `token ${token}` }});
            const login = context.repo.owner; const number = 3;
            const proj = await ghgql(`query($login:String!,$number:Int!){ user(login:$login){ projectV2(number:$number){ id fields(first:50){ nodes{ id name __typename ... on ProjectV2SingleSelectField { options{ id name } } } } } } }`, {login, number});
            const project = proj.user?.projectV2; if(!project){ core.warning('project not found'); return }
            const fields = project.fields.nodes;
            const F = (name)=>fields.find(f=>f.name===name);
            const O = (f,val)=> f && f.options && f.options.find(o=>o.name.toLowerCase()===(val||'').toLowerCase());
            const statusField = F('Status'); const priorityField = F('Priority');
            const statusOpt = O(statusField, status); const priorityOpt = O(priorityField, priority);
            const contentNodeId = (isPR
              ? (await github.rest.pulls.get({owner: context.repo.owner, repo: context.repo.repo, pull_number: item.number})).data.node_id
              : (await github.rest.issues.get({owner: context.repo.owner, repo: context.repo.repo, issue_number: item.number})).data.node_id);
            const addRes = await ghgql(`mutation($p:ID!,$c:ID!){ addProjectV2ItemById(input:{projectId:$p, contentId:$c}){ item{ id } } }`, {p: project.id, c: contentNodeId}).catch(()=>({}));
            const itemId = addRes?.addProjectV2ItemById?.item?.id; if(!itemId){ core.info('item exists or added already'); }
            async function setSelect(field,opt){ if(!field||!opt)return; await ghgql(`mutation($p:ID!,$i:ID!,$f:ID!,$o:String!){ updateProjectV2ItemFieldValue(input:{projectId:$p,itemId:$i,fieldId:$f,value:{singleSelectOptionId:$o}}){ clientMutationId } }`, {p: project.id, i: itemId, f: field.id, o: opt.id}); }
            await setSelect(statusField, statusOpt); await setSelect(priorityField, priorityOpt);
            core.info('mapped fields');
"""

PR_TEMPLATE = """## Summary
Explain the change.

## Checklist
- [ ] Semantic title
- [ ] Labels set (area/*, status/*, priority/*)
- [ ] Linked issue & milestone
- [ ] Tests/docs updated

## AI notes (if applicable)
Prompts, assumptions, citations.
"""

RELEASE_DRAFTER = """name-template: 'v$NEXT_PATCH_VERSION'
tag-template: 'v$NEXT_PATCH_VERSION'
change-template: '- $TITLE (#$NUMBER) by @$AUTHOR'
"""

RELEASE_DRAFTER_WF = """name: Release Drafter
on:
  push: { branches: [ $default-branch ] }
  pull_request: { types: [closed] }
  workflow_dispatch:
permissions: { contents: write }
jobs:
  update_release_draft:
    runs-on: ubuntu-latest
    steps:
      - uses: release-drafter/release-drafter@v6
        env: { GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} }
        with: { config-name: release-drafter.yml }
"""

DEPENDABOT = """version: 2
updates:
  - package-ecosystem: github-actions
    directory: /
    schedule: { interval: weekly }
  - package-ecosystem: pip
    directory: /
    schedule: { interval: weekly }
"""

CI_WF = """name: CI
on:
  pull_request:
  push: { branches: [ $default-branch ] }
  workflow_dispatch:
jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: { python-version: '3.11' }
      - name: Install tooling
        run: |
          python -m pip install --upgrade pip
          pip install ruff black pytest
      - name: Lint (ruff)
        run: ruff check . || true
      - name: Format (black)
        run: black --check . || true
      - name: Tests
        run: |
          if [ -d tests ]; then pytest -q; else echo "no tests"; fi
"""

# ==================================================================================
# milestone & PR utils
# ==================================================================================

def gh_find_milestone_number(title: str) -> str|None:
    if not shutil.which("gh"): return None
    rc, out, _ = run(["gh","api", f"repos/{REPO_SLUG}/milestones", "--paginate", "--jq", f'.[] | select(.title=="{title}") | .number'])
    if rc==0 and out.strip(): return out.strip().splitlines()[0]
    return None

def ensure_milestone(title: str, description: str, due_on_iso: str):
    if not shutil.which("gh"): return False
    num = gh_find_milestone_number(title)
    if num:
        run(["gh","api", f"repos/{REPO_SLUG}/milestones/{num}", "-X","PATCH", "-f", f"description={description}", "-f", f"due_on={due_on_iso}"])
        log(f"[OK] milestone '{title}' — updated"); return True
    rc, out, err = run(["gh","api", f"repos/{REPO_SLUG}/milestones", "-X","POST", "-f", f"title={title}", "-f", f"description={description}", "-f", f"due_on={due_on_iso}"])
    if rc==0: log(f"[APPLIED] milestone '{title}' — created"); return True
    if "already_exists" in (out+err) or "Validation Failed" in (out+err):
        log(f"[OK] milestone '{title}' — already existed"); return True
    log(f"[WARN] failed to create/update milestone '{title}'"); return False


def protect_branch(branch: str):
    if not shutil.which("gh"): return False
    payload = {
        "required_status_checks": {"strict": True, "contexts": ["Semantic Pull Request"]},
        "enforce_admins": False,
        "required_pull_request_reviews": {"required_approving_review_count": 1, "dismiss_stale_reviews": True},
        "restrictions": None,
        "allow_force_pushes": False,
        "allow_deletions": False,
        "required_linear_history": False,
    }
    tmp = Path(".tmp_protection.json"); tmp.write_text(json.dumps(payload), encoding="utf-8")
    rc, out, err = run(["gh","api", f"repos/{REPO_SLUG}/branches/{branch}/protection", "-X","PUT", "-H","Accept: application/vnd.github+json", "--input", str(tmp)])
    try: tmp.unlink(missing_ok=True)
    except Exception: pass
    if rc==0: log(f"[OK] branch protection updated on {branch}"); return True
    log(f"[WARN] branch protection failed: {err or out}"); return False

# ==================================================================================
# bootstrap workflows onto default branch if missing
# ==================================================================================

def workflows_on_default_branch() -> set[str]:
    rc, out, _ = run(["gh","workflow","list","--json","path","--jq",".[].path"])  # default branch only
    if rc!=0: return set()
    return set(out.splitlines()) if out else set()

BOOT_FILES = [
    ".github/workflows/semantic-pr.yml",
    ".github/workflows/auto-milestone.yml",
    ".github/labels.yml",
    ".github/workflows/labels-sync.yml",
    ".github/workflows/projects-sync.yml",
    ".github/release-drafter.yml",
    ".github/workflows/release-drafter.yml",
    ".github/dependabot.yml",
    ".github/workflows/ci.yml",
    ".github/pull_request_template.md",
    "CODEOWNERS",
    "CONTRIBUTING.md",
    "CODE_OF_CONDUCT.md",
    "scripts/labels_sync.py",
]

def bootstrap_default_branch_if_needed(current_branch: str, default_branch: str) -> bool:
    w = workflows_on_default_branch()
    needed = {".github/workflows/projects-sync.yml", ".github/workflows/ci.yml", ".github/workflows/release-drafter.yml"}
    if needed.issubset(w):
        log("[OK] workflows already present on default branch"); return False

    # Create micro-PR that copies files from current branch into default branch
    run(["git","fetch","origin"])
    run(["git","switch","-c","chore/bootstrap-workflows", f"origin/{default_branch}"])
    # Bring files over from current branch
    run(["git","checkout", current_branch, "--"] + BOOT_FILES)
    run(["git","add","-A"])
    rc, _, _ = run(["git","diff","--cached","--quiet"])  # rc=0 means nothing staged
    if rc==0:
        log("[OK] nothing to bootstrap");
    else:
        run(["git","commit","-m","chore(ci): bootstrap governance & workflows"])
        run(["git","push","-u","origin","chore/bootstrap-workflows"])
        # Open PR, approve, enable auto-merge
        rc, out, _ = run(["gh","pr","create","--base", default_branch, "--title","chore(ci): bootstrap governance & workflows","--body","Bring CI/Projects/Release workflows to default branch","--label","chore,status/Review,priority/P1"])
        pr_num = None
        m = re.search(r"/pull/(\d+)", out or "")
        if m: pr_num = m.group(1)
        if pr_num:
            run(["gh","pr","review", pr_num, "--approve"])  # self-approve
            run(["gh","pr","merge", pr_num, "--squash", "--auto"])  # let GH auto-merge when checks pass
            # Wait until merged (best-effort, 5 min)
            deadline = time.time() + 300
            while time.time() < deadline:
                rc, jout, _ = run(["gh","pr","view", pr_num, "--json","state,mergeStateStatus","--jq",".state + ' ' + .mergeStateStatus"])
                if rc==0 and jout.startswith("MERGED"):
                    log("[OK] bootstrap PR merged"); break
                time.sleep(8)
        # Return to original branch
        run(["git","switch", current_branch])
    return True

# ==================================================================================
# Self-test helpers (use workflow FILE names to avoid naming issues)
# ==================================================================================

def wait_for_workflow(workflow_file: str, timeout_s: int = 240) -> tuple[bool,str]:
    end = time.time() + timeout_s
    last_conclusion = ""
    while time.time() < end:
        rc, out, _ = run(["gh","run","list","-w", workflow_file, "-L","1","--json","status,conclusion,displayTitle,headSha"])
        try:
            runs = json.loads(out) if out else []
        except Exception:
            runs = []
        if runs:
            st = runs[0].get("status"); concl = runs[0].get("conclusion")
            if st == "completed":
                return (concl == "success", concl or "")
            last_conclusion = concl or last_conclusion
        time.sleep(6)
    return (False, last_conclusion or "timeout")


def projects_smoke(repo: str) -> bool:
    title = f"smoke: projects mapping ({ts()})"
    rc, out, _ = run(["gh","issue","create","-R", repo, "-t", title, "-b", "automated projects mapping smoke", "-l", "status/Todo,priority/P1"])
    if rc != 0 or not out:
        log("[FAIL] could not create issue"); return False
    # Kick the workflow manually in case label webhook races
    run(["gh","workflow","run","projects-sync.yml"])
    ok, concl = wait_for_workflow("projects-sync.yml")
    log(f"[projects] workflow: {concl}")
    # We cannot reliably read Project fields without a second query; success of the run is enough here.
    # Clean up issue best-effort
    m = re.search(r"/issues/(\d+)", out or ""); num = m.group(1) if m else None
    if num: run(["gh","issue","close",num,"-R",repo,"-c","smoke cleanup"])
    return ok


def ci_smoke() -> bool:
    run(["gh","workflow","run","ci.yml"])  # manual dispatch
    ok, concl = wait_for_workflow("ci.yml")
    log(f"[ci] workflow: {concl}")
    return ok


def release_drafter_smoke() -> bool:
    run(["gh","workflow","run","release-drafter.yml"])  # manual dispatch
    ok, concl = wait_for_workflow("release-drafter.yml")
    log(f"[release-drafter] workflow: {concl}")
    # Existence of a successful run is enough for smoke
    return ok

# ==================================================================================
# main
# ==================================================================================

def main():
    repo_dir = Path.cwd()
    current_branch = subprocess.run(["git","rev-parse","--abbrev-ref","HEAD"], capture_output=True, text=True).stdout.strip() or "HEAD"
    default_branch = get_default_branch()
    log(f"[info] repo={REPO_SLUG} default_branch={default_branch} apply={APPLY} self_test={SELF_TEST}")
    git_pull(repo_dir)

    # Governance & workflows
    wrote = False
    wrote |= ensure_file(repo_dir/"CONTRIBUTING.md", CONTRIBUTING)
    wrote |= ensure_file(repo_dir/"CODE_OF_CONDUCT.md", CODE_OF_CONDUCT)
    wrote |= ensure_file(repo_dir/"CODEOWNERS", "* @g0udurix\nstandards/** @g0udurix\nscripts/** @g0udurix\n.github/** @g0udurix\n")

    wrote |= ensure_file(repo_dir/".github"/"ISSUE_TEMPLATE"/"standards_mapping.md", "---\nname: Standards mapping task\nabout: Map clauses from CSA/ANSI/ISO/EN to topics & fragments\nlabels: [area/standards, status/Backlog]\n---\n\n## Standard & Clause(s)\n- Body (CSA/ANSI/ISO/EN/…):\n- Standard ID & year:\n- Clause numbers:\n\n## Linkage\n- Topics:\n- Fragments:\n\n## Notes\n- \n")
    wrote |= ensure_file(repo_dir/".github"/"ISSUE_TEMPLATE"/"comparison_task.md", "---\nname: Comparison/ranking task\nabout: Compare jurisdictions/standards on one subject\nlabels: [area/comparison, status/Todo]\n---\n\n## Subject\n## Scope (jurisdictions, standards)\n## Method\n## Done when\n- [ ] Data normalized\n- [ ] Summary added\n")
    wrote |= ensure_file(repo_dir/".github"/"pull_request_template.md", PR_TEMPLATE)

    wrote |= ensure_file(repo_dir/".github"/"workflows"/"semantic-pr.yml", SEMANTIC_PR_WF)
    wrote |= ensure_file(repo_dir/".github"/"workflows"/"auto-milestone.yml", AUTO_MILESTONE_WF)
    wrote |= ensure_file(repo_dir/".github"/"labels.yml", LABELS_YML)
    wrote |= ensure_file(repo_dir/".github"/"workflows"/"labels-sync.yml", LABELS_SYNC_WF)
    wrote |= ensure_file(repo_dir/".github"/"workflows"/"projects-sync.yml", PROJECTS_SYNC_WF)
    wrote |= ensure_file(repo_dir/".github"/"release-drafter.yml", RELEASE_DRAFTER)
    wrote |= ensure_file(repo_dir/".github"/"workflows"/"release-drafter.yml", RELEASE_DRAFTER_WF)
    wrote |= ensure_file(repo_dir/".github"/"dependabot.yml", DEPENDABOT)
    wrote |= ensure_file(repo_dir/".github"/"workflows"/"ci.yml", CI_WF)
    wrote |= ensure_file(repo_dir/"scripts"/"labels_sync.py", "#!/usr/bin/env python3\nprint('use GitHub Action labels-sync instead; manual script retained for emergencies')\n")

    wrote |= ensure_gitignore_lines(repo_dir, ['logs/', 'qdrant_storage/', '*.sqlite', '*.db', '*.db-journal', '__pycache__/', '*.pyc'])
    if APPLY and shutil.which('git'):
        run(["git","rm","-r","--cached","--ignore-unmatch","logs","qdrant_storage"], cwd=repo_dir)

    # Milestones (dates are relative to now)
    base = datetime.now(timezone.utc)
    for title, desc, due in [
        ("Phase 0 – Baseline", "Minimal viable schema, ingestion & search", base + timedelta(days=7)),
        ("Phase 1 – Corpus & Standards", "Import corpora, map CSA/ANSI/ISO", base + timedelta(days=45)),
        ("Phase 2 – Comparison Engine", "Matrix/ranking across jurisdictions", base + timedelta(days=75)),
        ("Phase 3 – Annotations & Issues", "Notes, flags, reviews, orientations", base + timedelta(days=105)),
        ("Phase 4 – Guidance UI", "Advices, cheat sheets, Q&A", base + timedelta(days=135)),
    ]:
        ensure_milestone(title, desc, due.strftime("%Y-%m-%dT%H:%M:%SZ"))

    # Branch protection
    protect_branch(default_branch)

    if APPLY:
        git_commit_push(repo_dir, f"chore(pm): governance + workflows refresh ({ts()})")

    # Ensure workflows active on default branch (so self-test can see them)
    bootstrap_default_branch_if_needed(current_branch, default_branch)

    # Self-test (optional)
    if SELF_TEST:
        print("\n===== SELF-TEST =====")
        proj_ok = projects_smoke(REPO_SLUG)
        ci_ok   = ci_smoke()
        rel_ok  = release_drafter_smoke()
        print("\nSelf-test results:")
        print(f"  Projects mapping: {'PASS' if proj_ok else 'FAIL'}")
        print(f"  CI workflow:      {'PASS' if ci_ok else 'FAIL'}")
        print(f"  Release drafter:  {'PASS' if rel_ok else 'FAIL'}")

if __name__ == "__main__":
    main()
